import copy
import os
import time
from datetime import datetime
from tqdm import tqdm
from multiprocessing import cpu_count

import numpy as np
import torch
import torch.nn as nn
from loguru import logger
from rich.console import Console
from rich.progress import (
    BarColumn,
    MofNCompleteColumn,
    Progress,
    SpinnerColumn,
    TextColumn,
    TimeRemainingColumn,
)
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from torch.cuda.amp import GradScaler

from loss import cross_entropy
from train import train_client_worker
from utils.tools import display_client_info
from utils.tools import get_all_metrics

# Richæ§åˆ¶å°
console = Console()


class FedTrain:
    """
    è”é‚¦å­¦ä¹ è®­ç»ƒç±»

    å®ç°è”é‚¦å­¦ä¹ çš„å®Œæ•´è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
    - å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼ˆæ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œï¼‰
    - æ¨¡å‹æƒé‡èšåˆï¼ˆFedAvgï¼‰
    - å…¨å±€æ¨¡å‹è¯„ä¼°ï¼ˆåŒ…å«è¯¦ç»†æŒ‡æ ‡å’Œå¯è§†åŒ–ï¼‰
    - æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
    """

    def __init__(
        self, args, model, train_loader: list, test_loader: dict, n_clients: int
    ):
        """
        åˆå§‹åŒ–è”é‚¦å­¦ä¹ è®­ç»ƒå™¨

        Args:
            args: è®­ç»ƒé…ç½®å‚æ•°
            model: å…¨å±€æ¨¡å‹
            train_loader: å„å®¢æˆ·ç«¯è®­ç»ƒæ•°æ®åŠ è½½å™¨åˆ—è¡¨ [dataloader0, dataloader1, ...]
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨å­—å…¸ {dataset_name: dataloader}
            n_clients: å®¢æˆ·ç«¯æ€»æ•°
        """
        self.args = args
        self.model = model.to(args.device)
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.args.n_clients = n_clients
        self.max_result = {
            "acc": 0.0,
            "loss": 0.0,
            "miou": 0.0,
            "iou_0": 0.0,
            "mf1": 0.0,
            "F1_0": 0.0,
            "F1_1": 0.0,
            "recall_0": 0.0,
            "recall_1": 0.0,
            "iou_1": 0.0,
            "precision_0": 0.0,
            "precision_1": 0.0,
        }


        # ä½¿ç”¨DataParallelè¿›è¡Œå¤šGPUå¹¶è¡ŒåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.device_count() > 1 and not args.device.startswith("cpu"):
            logger.info(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œè®­ç»ƒ")
            self.model = nn.DataParallel(self.model)

        # åˆ›å»ºæ¢¯åº¦ç¼©æ”¾å™¨ç”¨äºæ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = GradScaler()

        # åˆ›å»ºä¿å­˜æ¨¡å‹å’Œç»“æœçš„ç›®å½•
        self.save_dir = os.path.join(
            args.save_dir, f"fed_train_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        os.makedirs(self.save_dir, exist_ok=True)
        logger.info(f"æ¨¡å‹å’Œç»“æœå°†ä¿å­˜åˆ°: {self.save_dir}")

        # åˆå§‹åŒ–wandbï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import wandb

            self.wandb = wandb
            # å°è¯•è·å–å½“å‰çš„wandb run
            if wandb.run is not None:
                self.wandb_run = wandb.run
            else:
                self.wandb_run = None
            logger.info("WandBå·²åˆå§‹åŒ–")
        except ImportError:
            self.wandb = None
            self.wandb_run = None
            logger.warning("WandBæœªå®‰è£…ï¼Œå°†è·³è¿‡æ—¥å¿—è®°å½•")

    
        # è®°å½•æ¨¡å‹å‚æ•°åˆ°wandb
        if self.wandb is not None:
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(
                p.numel() for p in model.parameters() if p.requires_grad
            )
            self.wandb.config.update(
                {
                    "model_total_params": total_params,
                    "model_trainable_params": trainable_params,
                    "num_gpus": torch.cuda.device_count()
                    if torch.cuda.is_available()
                    else 0,
                    "device": args.device,
                }
            )

    def train_client(self, model, dataloader, client_idx, progress=None):
        """
        åœ¨å•ä¸ªå®¢æˆ·ç«¯ä¸Šè¿›è¡Œæœ¬åœ°è®­ç»ƒï¼ˆå•è¿›ç¨‹ç‰ˆæœ¬ï¼‰

        æ˜¾ç¤ºè¯¦ç»†çš„è®­ç»ƒè¿›åº¦ï¼ŒåŒ…æ‹¬epochçº§åˆ«å’Œbatchçº§åˆ«çš„è¿›åº¦

        Args:
            model: å®¢æˆ·ç«¯åˆå§‹æ¨¡å‹ï¼ˆå…¨å±€æ¨¡å‹çš„å‰¯æœ¬ï¼‰
            dataloader: å®¢æˆ·ç«¯è®­ç»ƒæ•°æ®åŠ è½½å™¨
            client_idx: å®¢æˆ·ç«¯ç´¢å¼•
            progress: Rich Progresså¯¹è±¡ï¼ˆå¯é€‰ï¼‰

        Returns:
            tuple: (è®­ç»ƒåçš„æ¨¡å‹, å¹³å‡æŸå¤±)
        """
        # æ·±æ‹·è´æ¨¡å‹ï¼Œé¿å…å½±å“å…¨å±€æ¨¡å‹
        client_model = copy.deepcopy(model)
        client_model.train()

        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(
            client_model.parameters(),
            lr=self.args.lr,
            betas=self.args.betas,
            eps=self.args.eps,
            weight_decay=self.args.weight_decay,
        )

        # åˆ›å»ºæ¢¯åº¦ç¼©æ”¾å™¨
        client_scaler = GradScaler()

        total_loss = 0.0
        num_batches = 0
        total_batches = len(dataloader) * self.args.num_client_epoch

        # åœ¨å®¢æˆ·ç«¯ä¸Šè¿›è¡Œå¤šä¸ªepochçš„æœ¬åœ°è®­ç»ƒ
        for epoch in range(self.args.num_client_epoch):
            epoch_start_time = time.time()
            epoch_loss = 0.0
            epoch_batches = 0
            epoch_task = None

            # åˆ›å»ºepochçº§åˆ«çš„è¿›åº¦æ¡
            if progress is not None:
                epoch_task = progress.add_task(
                    f"[cyan]å®¢æˆ·ç«¯ {client_idx} - Epoch {epoch + 1}/{self.args.num_client_epoch}",
                    total=len(dataloader),
                )
                iterator = dataloader
            else:
                # ä½¿ç”¨tqdm
                from tqdm import tqdm

                iterator = tqdm(
                    dataloader,
                    desc=f"å®¢æˆ·ç«¯ {client_idx} - Epoch {epoch + 1}/{self.args.num_client_epoch}",
                )

            for batch_idx, (A, B, Label, _) in enumerate(iterator):
                A = A.contiguous().to(self.args.device, non_blocking=True)
                B = B.contiguous().to(self.args.device, non_blocking=True)
                Label = Label.contiguous().to(self.args.device, non_blocking=True)

                optimizer.zero_grad(set_to_none=True)

                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰
                with torch.autocast(device_type=self.args.device, dtype=torch.float16):
                    pred = client_model(A, B)
                    loss = cross_entropy(pred[0].contiguous(), Label)

                client_scaler.scale(loss).backward()
                client_scaler.step(optimizer)
                client_scaler.update()

                total_loss += loss.item()
                epoch_loss += loss.item()
                num_batches += 1
                epoch_batches += 1

                # æ›´æ–°Richè¿›åº¦æ¡
                if progress is not None and epoch_task is not None:
                    progress.update(
                        epoch_task,
                        advance=1,
                        description=f"[cyan]å®¢æˆ·ç«¯ {client_idx} - Epoch {epoch + 1}/{self.args.num_client_epoch} - Loss: {loss.item():.4f}",
                    )

            epoch_time = time.time() - epoch_start_time
            avg_epoch_loss = epoch_loss / epoch_batches if epoch_batches > 0 else 0.0

            logger.info(
                f"    å®¢æˆ·ç«¯ {client_idx} - Epoch {epoch + 1}/{self.args.num_client_epoch} å®Œæˆï¼ŒæŸå¤±: {avg_epoch_loss:.4f}, è€—æ—¶: {epoch_time:.2f}ç§’"
            )

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / (num_batches * self.args.num_client_epoch)

        return client_model, avg_loss

    def train_clients_parallel(self, selected_client_indices, progress=None):
        """
        ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œè®­ç»ƒå¤šä¸ªå®¢æˆ·ç«¯

        å¤šè¿›ç¨‹å¹¶è¡Œå¯ä»¥æ˜¾è‘—æé«˜è®­ç»ƒé€Ÿåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å®¢æˆ·ç«¯æ•°é‡è¾ƒå¤šæ—¶

        Args:
            selected_client_indices: é€‰ä¸­çš„å®¢æˆ·ç«¯ç´¢å¼•åˆ—è¡¨
            progress: Rich Progresså¯¹è±¡ï¼ˆå¯é€‰ï¼‰

        Returns:
            tuple: (å®¢æˆ·ç«¯æ¨¡å‹çŠ¶æ€å­—å…¸åˆ—è¡¨, å®¢æˆ·ç«¯æŸå¤±åˆ—è¡¨)
        """
        import multiprocessing as mp

        # è·å–å…¨å±€æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        global_state_dict = self.model.state_dict()

        # å‡†å¤‡æ¯ä¸ªå®¢æˆ·ç«¯çš„å‚æ•°
        client_args = []
        for idx in selected_client_indices:
            client_args.append(
                (
                    copy.deepcopy(global_state_dict),
                    idx,
                    self.args,
                    idx,
                    self.train_loader,
                )
            )

        # ç¡®å®šä½¿ç”¨çš„è¿›ç¨‹æ•°
        n_workers = min(
            self.args.n_workers if hasattr(self.args, "n_workers") else cpu_count(),
            len(selected_client_indices),
        )
        logger.info(
            f"ä½¿ç”¨ {n_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œè®­ç»ƒ {len(selected_client_indices)} ä¸ªå®¢æˆ·ç«¯"
        )

        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œè®­ç»ƒå®¢æˆ·ç«¯
        # æ³¨æ„ï¼šåœ¨Linux/WSLä¸Šä½¿ç”¨CUDAéœ€è¦ä½¿ç”¨'spawn' start method
        ctx = mp.get_context("spawn")
        client_models = []
        client_losses = []

        with ctx.Pool(processes=n_workers) as pool:
            # å¦‚æœæœ‰è¿›åº¦æ¡å¯¹è±¡ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨tqdm
            if progress is not None:
                # ä½¿ç”¨å¤–éƒ¨è¿›åº¦æ¡
                task = progress.add_task(
                    "[cyan]å¹¶è¡Œè®­ç»ƒå®¢æˆ·ç«¯ä¸­...", total=len(client_args)
                )
                results = []
                for result in pool.imap(train_client_worker, client_args):
                    results.append(result)
                    progress.update(task, advance=1)
            else:
                # ä½¿ç”¨tqdmï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰
                from tqdm import tqdm

                results = list(
                    tqdm(
                        pool.imap(train_client_worker, client_args),
                        total=len(client_args),
                        desc="å¹¶è¡Œè®­ç»ƒå®¢æˆ·ç«¯",
                    )
                )

        for i, (state_dict, loss) in enumerate(results):
            client_models.append(state_dict)
            client_losses.append(loss)
            logger.info(f"  å®¢æˆ·ç«¯ {selected_client_indices[i]} è®­ç»ƒæŸå¤±: {loss:.4f}")

        return client_models, client_losses

    def average_weights(self, clients_model: list, client_weights=None):
        """
        ä½¿ç”¨FedAvgç®—æ³•èšåˆå®¢æˆ·ç«¯æ¨¡å‹æƒé‡

        Args:
            clients_model: å®¢æˆ·ç«¯æ¨¡å‹çŠ¶æ€å­—å…¸åˆ—è¡¨ [state_dict1, state_dict2, ...]
            client_weights: å®¢æˆ·ç«¯æƒé‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å¹³å‡æƒé‡

        Returns:
            dict: èšåˆåçš„å…¨å±€æ¨¡å‹çŠ¶æ€å­—å…¸
        """
        if not clients_model:
            logger.warning("æ²¡æœ‰å®¢æˆ·ç«¯æ¨¡å‹éœ€è¦èšåˆ")
            return self.model.state_dict()

        # è®¡ç®—æ¯ä¸ªå®¢æˆ·ç«¯çš„æƒé‡
        if client_weights is None:
            client_weights = [1.0 / len(clients_model)] * len(clients_model)
        else:
            total_weight = sum(client_weights)
            client_weights = [w / total_weight for w in client_weights]

        # åˆå§‹åŒ–èšåˆåçš„æƒé‡å­—å…¸
        avg_weights = clients_model[0].copy()

        # å¯¹æ¯ä¸ªå‚æ•°è¿›è¡ŒåŠ æƒå¹³å‡
        for key in avg_weights.keys():
            avg_weights[key] = avg_weights[key] * client_weights[0]

            for i in range(1, len(clients_model)):
                avg_weights[key] += clients_model[i][key] * client_weights[i]

        return avg_weights

    def evaluate_model(
        self, model, test_loader, ds_name, save_samples=True, progress=None
    ):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆåŒ…å«è¯¦ç»†æŒ‡æ ‡å’Œå¯è§†åŒ–ï¼‰

        Args:
            model: è¦è¯„ä¼°çš„æ¨¡å‹
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            ds_name: æ•°æ®é›†åç§°
            save_samples: æ˜¯å¦ä¿å­˜é¢„æµ‹æ ·æœ¬
            progress: Rich Progresså¯¹è±¡ï¼ˆå¯é€‰ï¼‰
        """
        model.eval()

        all_preds = []
        all_labels = []
        total_loss = 0.0
        num_samples = 0

        inference_times = []

        with torch.no_grad():
            for A, B, Label, _ in tqdm(test_loader, total=len(test_loader)):
                A = A.contiguous().to(self.args.device, non_blocking=True)
                B = B.contiguous().to(self.args.device, non_blocking=True)
                Label = Label.contiguous().to(self.args.device, non_blocking=True)

                start_time = time.time()

                with torch.autocast(device_type=self.args.device, dtype=torch.float16):
                    pred = model(A, B)
                    loss = cross_entropy(pred[0].contiguous(), Label)

                inference_time = time.time() - start_time
                inference_times.append(inference_time)

                total_loss += loss.item() * A.size(0)
                num_samples += A.size(0)

                all_preds.append(pred[0].cpu())
                all_labels.append(Label.cpu())

        all_preds = torch.cat(all_preds, dim=0).cpu()
        all_labels= torch.cat(all_labels, dim=0).cpu()

        result_dict = get_all_metrics(pred=all_preds, label=all_labels)
        # è®¡ç®—æ¨ç†é€Ÿåº¦

        # è®°å½•æµ‹è¯•æŒ‡æ ‡åˆ°wandb
        if self.wandb is not None:
            prefix = f"test/{ds_name}"
            self.wandb.log(
               result_dict 
            )

        return result_dict 

    def save_model(self, model, epoch, is_best=False):
        """
        ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶
        """
        checkpoint = {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "config": vars(self.args),
        }

        save_path = os.path.join(self.save_dir, f"model_epoch_{epoch}.pth")
        torch.save(checkpoint, save_path)
        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")

        # è®°å½•æ¨¡å‹åˆ°wandb
        if self.wandb is not None:

            self.wandb.save(save_path, base_path=self.save_dir)

        if is_best:
            best_path = os.path.join(self.save_dir, "model_best.pth")
            torch.save(checkpoint, best_path)
            logger.info(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {best_path}")

            # è®°å½•æœ€ä½³æ¨¡å‹åˆ°wandb
            if self.wandb is not None:
                self.wandb.save(best_path, base_path=self.save_dir)

    def load_model(self, checkpoint_path):
        """
        ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
        """
        if not os.path.exists(checkpoint_path):
            logger.warning(f"checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return 0

        checkpoint = torch.load(checkpoint_path, map_location=self.args.device)
        self.model.load_state_dict(checkpoint["model_state_dict"])

        epoch = checkpoint.get("epoch", 0)
        logger.info(f"å·²ä» {checkpoint_path} åŠ è½½æ¨¡å‹ï¼Œepoch: {epoch}")

        return epoch

    def test(self, progress=None):
        """
        åœ¨æ‰€æœ‰æµ‹è¯•æ•°æ®é›†ä¸Šè¯„ä¼°å…¨å±€æ¨¡å‹æ€§èƒ½

        Args:
            progress: Rich Progresså¯¹è±¡ï¼ˆå¯é€‰ï¼‰
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹æµ‹è¯•å…¨å±€æ¨¡å‹...")
        logger.info("=" * 60)

        metrics = self.evaluate_model(
            self.model,
            self.test_loader,
            "TESTSET",
            save_samples=True,
            progress=progress,
        )


    def start_train(self):
        """
        å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒæµç¨‹
        """
        # ä½¿ç”¨Richæ˜¾ç¤ºè®­ç»ƒé…ç½®
        console.print("\n[bold blue]è®­ç»ƒé…ç½®[/bold blue]")
        console.print(f"  å®¢æˆ·ç«¯æ€»æ•°: [cyan]{self.args.n_clients}[/cyan]")
        console.print(f"  æ¯è½®å‚ä¸å®¢æˆ·ç«¯æ¯”ä¾‹: [cyan]{self.args.frac}[/cyan]")
        console.print(f"  è®­ç»ƒè½®æ•°: [cyan]{self.args.num_epochs}[/cyan]")
        console.print(
            f"  å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒè½®æ•°: [cyan]{self.args.num_client_epoch}[/cyan]"
        )
        console.print(
            f"  è¯„ä¼°é—´éš”: [cyan]æ¯ {self.args.eval_interval} è½®è¯„ä¼°ä¸€æ¬¡[/cyan]"
        )
        console.print(
            f"  ä½¿ç”¨å¹¶è¡Œè®­ç»ƒ: [cyan]{getattr(self.args, 'use_parallel', True)}[/cyan]"
        )

        train_losses = []
        best_f1 = 0.0

        # ä½¿ç”¨Richè¿›åº¦æ¡æ˜¾ç¤ºæ•´ä½“è®­ç»ƒè¿›åº¦
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            MofNCompleteColumn(),
            TimeRemainingColumn(),
            console=console,
        ) as progress:
            # åˆ›å»ºæ€»ä½“è®­ç»ƒä»»åŠ¡
            overall_task = progress.add_task(
                "[bold green]è”é‚¦å­¦ä¹ è®­ç»ƒè¿›åº¦", total=self.args.num_epochs
            )

            for round_idx in range(self.args.num_epochs):
                self.current_round = round_idx  # ç”¨äºwandbæ—¥å¿—è®°å½•
                round_start_time = time.time()

                progress.console.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
                progress.console.print(
                    f"[bold cyan]è®­ç»ƒè½®æ¬¡: {round_idx + 1}/{self.args.num_epochs}[/bold cyan]"
                )
                progress.console.print(f"[bold cyan]{'=' * 60}[/bold cyan]")

                # éšæœºé€‰æ‹©å‚ä¸æœ¬è½®è®­ç»ƒçš„å®¢æˆ·ç«¯
                m = max(int(self.args.frac * self.args.n_clients), 1)
                selected_client_indices = np.random.choice(
                    range(self.args.n_clients), m, replace=False
                )

                logger.info(f"æœ¬è½®é€‰ä¸­çš„å®¢æˆ·ç«¯: {selected_client_indices.tolist()}")

                # è®°å½•è®­ç»ƒé…ç½®åˆ°wandb
                if self.wandb is not None and round_idx == 0:
                    self.wandb.config.update(
                        {
                            "selected_clients_per_round": m,
                            "total_clients": self.args.n_clients,
                            "client_fraction": self.args.frac,
                        }
                    )

                client_models = []
                client_losses = []

                use_parallel = getattr(self.args, "use_parallel", True)

                if use_parallel:
                    client_models, client_losses = self.train_clients_parallel(
                        selected_client_indices, progress
                    )
                else:
                    for client_idx in selected_client_indices:
                        logger.info(f"  è®­ç»ƒå®¢æˆ·ç«¯ {client_idx}...")

                        client_model, client_loss = self.train_client(
                            model=self.model,
                            dataloader=self.train_loader[client_idx],
                            client_idx=client_idx,
                            progress=progress,
                        )

                        client_models.append(client_model.state_dict())
                        client_losses.append(client_loss)

                        logger.info(
                            f"  å®¢æˆ·ç«¯ {client_idx} è®­ç»ƒæŸå¤±: {client_loss:.4f}"
                        )

                        # è®°å½•å®¢æˆ·ç«¯æŸå¤±åˆ°wandb
                        if self.wandb is not None:
                            self.wandb.log(
                                {
                                    f"train/round_{round_idx}/client_{client_idx}_loss": client_loss,
                                },
                                step=round_idx,
                            )

                # èšåˆå®¢æˆ·ç«¯æ¨¡å‹å‚æ•°
                updated_weights = self.average_weights(client_models)
                self.model.load_state_dict(updated_weights)

                # è®¡ç®—æœ¬è½®å¹³å‡æŸå¤±
                round_avg_loss = sum(client_losses) / len(client_losses)
                train_losses.append(round_avg_loss)

                round_time = time.time() - round_start_time

                # è®°å½•è½®æ¬¡çº§åˆ«æŒ‡æ ‡åˆ°wandb
                if self.wandb is not None:
                    import wandb

                    self.wandb.log(
                        {
                            "train/round_loss": round_avg_loss,
                            "train/round_time": round_time,
                            "train/clients_per_second": m / round_time,
                            "train/selected_clients": selected_client_indices.tolist(),
                        },
                        step=round_idx,
                    )

                # ä½¿ç”¨Richæ˜¾ç¤ºæœ¬è½®è®­ç»ƒç»“æœ
                progress.console.print(
                    f"\n[bold yellow]è½®æ¬¡ {round_idx + 1} æ€»ç»“:[/bold yellow]"
                )
                progress.console.print(
                    f"  - å¹³å‡è®­ç»ƒæŸå¤±: [red]{round_avg_loss:.4f}[/red]"
                )
                progress.console.print(
                    f"  - æœ¬è½®è€—æ—¶: [cyan]{round_time:.2f}[/cyan] ç§’"
                )
                progress.console.print(
                    f"  - è®­ç»ƒé€Ÿåº¦: [cyan]{m / round_time:.2f}[/cyan] å®¢æˆ·ç«¯/ç§’"
                )

                # æ›´æ–°æ€»ä½“è¿›åº¦
                progress.update(overall_task, advance=1)

                # å®šæœŸè¯„ä¼°æ¨¡å‹
                if round_idx % self.args.eval_interval == 0:

                    test_metrics = self.test(progress=progress)



def main():
    """
    ä¸»å‡½æ•°ï¼šå¯åŠ¨è”é‚¦å­¦ä¹ è®­ç»ƒæµç¨‹
    """
    from datetime import datetime

    from loguru import logger

    import wandb
    from assgin_ds import get_fed_dataloaders_with_allocator
    from backbone.BaseTransformer import BASE_Transformer
    from utils.args import get_fed_config

    wandb.login()
    fed_config = get_fed_config()

    project_name = "change-detection-demo"

    ds_name = {
        "LEVIR": {
            "path": fed_config.datasets + "/LEVIR",
            "n_clients": 2,
            "data_ratios": [0.6, 0.4],
            "sampler_configs": [
                {"type": "random", "shuffle": True},
                {"type": "weighted", "shuffle": True, "weights": None},
            ],
        },
        "S2Looking": {
            "path": fed_config.datasets + "/S2Looking",
            "n_clients": 4,
            "data_ratios": [0.5, 0.3, 0.15, 0.05],
            "sampler_configs": [
                {"type": "random", "shuffle": True},
                {"type": "sequential"},
                {"type": "random", "shuffle": True},
                {"type": "weighted", "shuffle": True, "weights": None},
            ],
        },
        "WHUCD": {
            "path": fed_config.datasets + "/WHUCD",
            "n_clients": 2,
            "data_ratios": [0.5, 0.5],
            "sampler_configs": [
                {"type": "random", "shuffle": True},
                {"type": "sequential"},
            ],
        },
    }

    if __name__ == "__main__":
        # å°†é…ç½®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        config_dict = vars(fed_config)

        with wandb.init(project=project_name, config=config_dict) as run:

            print(f"\n{'=' * 60}")

            # ========== ç¬¬1æ­¥ï¼šåŠ è½½æ•°æ®é›† ==========
            console.print("[bold blue]æ­£åœ¨åŠ è½½æ•°æ®é›†...[/bold blue]")
            from assgin_ds import get_fed_dataset

            train_dict, test_dict = get_fed_dataset(args=fed_config, ds_name=ds_name)

            train_loaders, test_loader, client_info = (
                get_fed_dataloaders_with_allocator(
                    train_datasets=train_dict,
                    test_datasets=test_dict,
                    ds_name=ds_name,
                    args=fed_config,
                )
            )

            console.print("\n[bold green]âœ… æ•°æ®åˆ†é…å®Œæˆï¼[/bold green]")
            console.print(f"æ€»å®¢æˆ·ç«¯æ•°: [cyan]{len(train_loaders)}[/cyan]")
            console.print(f"æµ‹è¯•æ•°æ®é›†æ•°: [cyan]{len(test_loader)}[/cyan]")

            # æ˜¾ç¤ºæ‰€æœ‰å®¢æˆ·ç«¯çš„è®­ç»ƒæ ·æœ¬å’Œé‡‡æ ·æ¨¡å¼ä¿¡æ¯
            display_client_info(train_loaders, ds_name)

            tot_client = 0
            current_client_id = 0

            for ds_name, ds_info in ds_name.items():
                n_clients = ds_info["n_clients"]
                tot_client += n_clients
                current_client_id += n_clients

            # ========== ç¬¬2æ­¥ï¼šåˆå§‹åŒ–æ¨¡å‹ ==========
            console.print("\n[bold blue]æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...[/bold blue]")

            model = BASE_Transformer(
                input_nc=3,
                output_nc=2,
                token_len=4,
                resnet_stages_num=4,
                with_pos="learned",
                enc_depth=1,
                dec_depth=8,
            )

            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(
                p.numel() for p in model.parameters() if p.requires_grad
            )
            console.print(f"  - æ€»å‚æ•°é‡: [cyan]{total_params:,}[/cyan]")
            console.print(f"  - å¯è®­ç»ƒå‚æ•°é‡: [cyan]{trainable_params:,}[/cyan]")
            console.print("[bold green]âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼[/bold green]\n")

            # ========== ç¬¬3æ­¥ï¼šå¯åŠ¨è”é‚¦å­¦ä¹ è®­ç»ƒ ==========
            logger.info(f"å®¢æˆ·ç«¯æ•°é‡: {tot_client}")

            Trainer = FedTrain(
                args=fed_config,
                model=model,
                train_loader=train_loaders,
                test_loader=test_loader,
                n_clients=tot_client,
            )

            Trainer.start_train()
            console.print("\n[bold green]ğŸ‰ è®­ç»ƒå®Œæˆï¼[/bold green]")


if __name__ == "__main__":
    logger.add('logs/{time}'+ '.log',
            rotation='50 MB', level='DEBUG')
    main()
